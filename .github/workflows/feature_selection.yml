import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# ===============================
# ë°ì´í„° ë¡œë“œ
# ===============================
df = pd.read_csv("data/raw_data.csv")

# ===============================
# íƒ€ê²Ÿ ì„ íƒ
# 1ì°¨ ì„±ê³µ í™•ë¥  ëª¨ë¸
# ===============================
y = df["Success_1st"]

# ì „ëµ ê²°ê³¼ ì»¬ëŸ¼ ì œê±°
drop_cols = [
    "Ticker",
    "Success_1st",
    "Return_1st",
    "Hold_days_1st",
    "Second_phase_used",
    "Return_final",
    "Hold_days_final",
    "Max_hold_days",
    "Max_drawdown"
]

X = df.drop(columns=drop_cols)

# ===============================
# ëª¨ë¸ í•™ìŠµ
# ===============================
model = RandomForestClassifier(
    n_estimators=500,
    max_depth=8,
    random_state=42,
    n_jobs=-1
)

model.fit(X, y)

# ===============================
# ì¤‘ìš”ë„ ì¶”ì¶œ
# ===============================
importances = pd.Series(
    model.feature_importances_,
    index=X.columns
).sort_values(ascending=False)

print("\nğŸ”¥ Feature Importance")
print(importances.head(15))

# ===============================
# ìƒìœ„ 8~12ê°œ ì„ íƒ
# ===============================
top_features = importances.head(12).index.tolist()

print("\nâœ… ì„ íƒëœ í•µì‹¬ ì§€í‘œ:")
for f in top_features:
    print(f)
